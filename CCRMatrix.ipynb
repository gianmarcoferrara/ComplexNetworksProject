{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632cb43d-8681-47c7-b168-310fe408b359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1001.0    1003.0    1005.0    1007.0    1009.0    1011.0    1013.0  \\\n",
      "1001.0  0.000000  0.850792  0.783337  0.859640  0.879769  0.748210  0.906328   \n",
      "1003.0  0.850792  0.000000  0.961628  0.964526  0.958348  0.909740  0.944460   \n",
      "1005.0  0.783337  0.961628  0.000000  0.928717  0.912884  0.916322  0.900017   \n",
      "1007.0  0.859640  0.964526  0.928717  0.000000  0.947723  0.903281  0.924158   \n",
      "1009.0  0.879769  0.958348  0.912884  0.947723  0.000000  0.855754  0.936804   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "6077.0  0.556566  0.539095  0.621070  0.531150  0.543095  0.522629  0.511127   \n",
      "6079.0  0.508377  0.527379  0.601322  0.521439  0.525572  0.527956  0.501933   \n",
      "6081.0  0.469259  0.501077  0.563153  0.532610  0.510174  0.527076  0.507064   \n",
      "6083.0  0.539697  0.530258  0.595904  0.565548  0.564104  0.527953  0.522171   \n",
      "6085.0  0.492503  0.537158  0.610902  0.515583  0.477808  0.520825  0.475322   \n",
      "\n",
      "          1015.0    1017.0    1019.0  ...    6067.0    6069.0    6071.0  \\\n",
      "1001.0  0.891347  0.770100  0.831535  ...  0.522788  0.622259  0.625306   \n",
      "1003.0  0.979194  0.924617  0.955950  ...  0.494718  0.616586  0.624702   \n",
      "1005.0  0.937527  0.933636  0.938147  ...  0.577208  0.623796  0.639792   \n",
      "1007.0  0.966785  0.882176  0.947517  ...  0.517046  0.632833  0.635859   \n",
      "1009.0  0.975397  0.891829  0.948447  ...  0.517704  0.641319  0.652885   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "6077.0  0.577821  0.639827  0.585760  ...  0.950975  0.965154  0.962895   \n",
      "6079.0  0.565011  0.605783  0.581092  ...  0.980360  0.967729  0.955657   \n",
      "6081.0  0.536168  0.607377  0.548367  ...  0.964638  0.909944  0.883815   \n",
      "6083.0  0.601042  0.616289  0.623771  ...  0.969463  0.976544  0.967522   \n",
      "6085.0  0.515477  0.622990  0.531468  ...  0.916007  0.892117  0.894831   \n",
      "\n",
      "          6073.0    6075.0    6077.0    6079.0    6081.0    6083.0    6085.0  \n",
      "1001.0  0.531323  0.569132  0.587606  0.540181  0.497313  0.569846  0.508812  \n",
      "1003.0  0.608242  0.600783  0.541489  0.529716  0.501553  0.556408  0.536640  \n",
      "1005.0  0.661521  0.635419  0.625907  0.605969  0.565127  0.600198  0.610440  \n",
      "1007.0  0.582584  0.627974  0.553280  0.547270  0.534124  0.590888  0.513931  \n",
      "1009.0  0.547718  0.607368  0.563951  0.549171  0.510675  0.585839  0.474059  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "6077.0  0.634747  0.908831  0.000000  0.969191  0.904201  0.984878  0.933928  \n",
      "6079.0  0.594275  0.940415  0.969191  0.000000  0.945697  0.981175  0.910416  \n",
      "6081.0  0.603608  0.956968  0.904201  0.945697  0.000000  0.938818  0.925442  \n",
      "6083.0  0.618129  0.948444  0.984878  0.981175  0.938818  0.000000  0.932083  \n",
      "6085.0  0.670153  0.881606  0.933928  0.910416  0.925442  0.932083  0.000000  \n",
      "\n",
      "[200 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import correlate\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "\n",
    "# Load the temporal series data\n",
    "data_with_date = pd.read_csv('temporal_series_20.csv')\n",
    "data = data_with_date.drop(columns=['date'])\n",
    "\n",
    "\n",
    "\n",
    "def time_delayed_cross_correlation(N_i, N_j, max_tau):\n",
    "    \"\"\"\n",
    "    Computes the time-delayed cross-correlation function for two time series N_i and N_j.\n",
    "    \n",
    "    Args:\n",
    "    N_i (numpy array): Time series for node i.\n",
    "    N_j (numpy array): Time series for node j.\n",
    "    max_tau (int): Maximum time delay (positive or negative).\n",
    "    \n",
    "    Returns:\n",
    "    cross_corrs (numpy array): Cross-correlation values for each time delay in the range [-max_tau, max_tau].\n",
    "    time_lags (numpy array): Corresponding time lags.\n",
    "    \"\"\"\n",
    "    n = len(N_i)\n",
    "    mean_i = np.mean(N_i)\n",
    "    mean_j = np.mean(N_j)\n",
    "    \n",
    "    # Prepare arrays for cross-correlations and time lags\n",
    "    cross_corrs = []\n",
    "    time_lags = range(-max_tau, max_tau + 1)\n",
    "    \n",
    "    for tau in time_lags:\n",
    "        if tau < 0:\n",
    "            shifted_j = np.roll(N_j, tau)  # shift N_j forward (N_j(t+τ))\n",
    "            valid_indices = np.arange(-tau, n)  # indices where the time shift is valid\n",
    "        else:\n",
    "            shifted_i = np.roll(N_i, -tau)  # shift N_i backward (N_i(t-τ))\n",
    "            valid_indices = np.arange(0, n - tau)  # indices where the time shift is valid\n",
    "\n",
    "        # Calculate the cross-correlation for the valid time points\n",
    "        if tau < 0:\n",
    "            numerator = np.mean(N_i[valid_indices] * shifted_j[valid_indices]) - mean_i * mean_j\n",
    "            denominator = np.std(N_i[valid_indices]) * np.std(shifted_j[valid_indices])\n",
    "        else:\n",
    "            numerator = np.mean(shifted_i[valid_indices] * N_j[valid_indices]) - mean_i * mean_j\n",
    "            denominator = np.std(shifted_i[valid_indices]) * np.std(N_j[valid_indices])\n",
    "        \n",
    "        # Handle the case where the denominator is zero\n",
    "        if denominator != 0:\n",
    "            corr = numerator / denominator\n",
    "        else:\n",
    "            corr = 0\n",
    "        \n",
    "        cross_corrs.append(corr)    \n",
    "    \n",
    "    return np.array(cross_corrs), np.array(time_lags) \n",
    "\n",
    "\n",
    "#We have a problem because sround 3000 columns is too much, first let's see what happens with a subset\n",
    "#Now we will make a test for the first 50 columns\n",
    "time_series_subset = data.iloc[:, :200]\n",
    "\n",
    "#Inizialize parameters\n",
    "max_tau = 15 \n",
    "threshold = 0.05\n",
    "\n",
    "#Let's compute the cross correlation function for each pair of columns in the subset\n",
    "subset_columns = time_series_subset.columns\n",
    "#To store results\n",
    "adjacency_matrix = np.zeros((len(subset_columns), len(subset_columns)))\n",
    "                            \n",
    "for i in range(len(subset_columns)):\n",
    "        for j in range(len(subset_columns)):\n",
    "            if i != j:\n",
    "                N_i = time_series_subset.iloc[:,i].values\n",
    "                N_j = time_series_subset.iloc[:,j].values\n",
    "                cross_corrs, _ = time_delayed_cross_correlation(N_i, N_j, max_tau)\n",
    "                #Now we store the results\n",
    "                max_corr = np.max(cross_corrs)\n",
    "                if max_corr >= threshold:\n",
    "                    adjacency_matrix[i,j] = max_corr\n",
    "\n",
    "\n",
    "adj_data = pd.DataFrame(adjacency_matrix, index=subset_columns, columns=subset_columns)\n",
    "print(adj_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
