{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25981d-a03b-4590-a140-5d29f13e525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import correlate\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "\n",
    "# Load the temporal series data\n",
    "data_with_date = pd.read_csv('temporal_series_20.csv')\n",
    "data = data_with_date.drop(columns=['date'])\n",
    "\n",
    "#Inizialize parameters\n",
    "max_tau = 15 \n",
    "threshold = 0.05\n",
    "\n",
    "def time_delayed_cross_correlation(df, col1, col2, max_tau):\n",
    "    \"\"\"\n",
    "    Computes the time-delayed cross-correlation function for two time series N_i and N_j.\n",
    "    \n",
    "    Args:\n",
    "    N_i (numpy array): Time series for node i.\n",
    "    N_j (numpy array): Time series for node j.\n",
    "    max_tau (int): Maximum time delay (positive or negative).\n",
    "    \n",
    "    Returns:\n",
    "    cross_corrs (numpy array): Cross-correlation values for each time delay in the range [-max_tau, max_tau].\n",
    "    time_lags (numpy array): Corresponding time lags.\n",
    "    \"\"\"\n",
    "    n = len(col1)\n",
    "    mean_i = df[col1].mean()\n",
    "    mean_j = df[col2].mean()\n",
    "    \n",
    "    # Prepare arrays for cross-correlations and time lags\n",
    "    cross_corrs = []\n",
    "    time_lags = range(-max_tau, max_tau + 1)\n",
    "    \n",
    "    for tau in time_lags:\n",
    "        if tau < 0:\n",
    "            shifted_j = np.roll(df[col2], tau)  # shift N_j forward (N_j(t+τ))\n",
    "            valid_indices = np.arange(-tau, n)  # indices where the time shift is valid\n",
    "        else:\n",
    "            shifted_i = np.roll(df[col1], -tau)  # shift N_i backward (N_i(t-τ))\n",
    "            valid_indices = np.arange(0, n - tau)  # indices where the time shift is valid\n",
    "\n",
    "        # Calculate the cross-correlation for the valid time points\n",
    "        if tau < 0:\n",
    "            numerator = np.mean(df[col1][valid_indices] * shifted_j[valid_indices]) - mean_i * mean_j\n",
    "            denominator = np.std(df[col1][valid_indices]) * np.std(shifted_j[valid_indices])\n",
    "        else:\n",
    "            numerator = np.mean(shifted_i[valid_indices] * df[col2][valid_indices]) - mean_i * mean_j\n",
    "            denominator = np.std(shifted_i[valid_indices]) * np.std(df[col2][valid_indices])\n",
    "        \n",
    "        # Handle the case where the denominator is zero\n",
    "        if denominator != 0:\n",
    "            corr = numerator / denominator\n",
    "        else:\n",
    "            corr = 0\n",
    "        \n",
    "        cross_corrs.append(corr)    \n",
    "    max_corr = np.max(cross_corrs)\n",
    "    if max_corr >= threshold:\n",
    "        return max_corr\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Function to compute the whole adjacency matrix (impossible to compute)\n",
    "def ccr_matrix(df):\n",
    "    #build the adjacency matrix\n",
    "    adjacency_matrix = pd.DataFrame(np.nan, index=df.columns, columns=df.columns)\n",
    "\n",
    "    #iterate for each pair of columns\n",
    "    for col1 in df.columns:\n",
    "        for col2 in df.columns:\n",
    "            adjacency_matrix.loc[col1,col2] =time_delayed_cross_correlation(df, col1, col2, max_tau)\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "#function to compute just a submatrix of the adjacency matrix\n",
    "def compute_submatrix(df, columns, filename):\n",
    "    submatrix = pd.DataFrame(index=columns, columns=columns)\n",
    "    for col1, col2 in product(columns, repeat=2):\n",
    "        submatrix.loc[col1,col2]\n",
    "#We have a problem because around 3105 columns is too much, first let's see what happens with a subset\n",
    "#Now we will make a test for the first 50 columns\n",
    "time_series_subset = data.iloc[:, :10]\n",
    "\n",
    "\n",
    "#Let's compute the cross correlation function for each pair of columns in the subset\n",
    "subset_columns = time_series_subset.columns\n",
    "#To store results\n",
    "adjacency_matrix = np.zeros((len(subset_columns), len(subset_columns)))\n",
    "                            \n",
    "for i in range(len(subset_columns)):\n",
    "        for j in range(len(subset_columns)):\n",
    "            if i != j:\n",
    "                N_i = time_series_subset.iloc[:,i].values\n",
    "                N_j = time_series_subset.iloc[:,j].values\n",
    "                cross_corrs, _ = time_delayed_cross_correlation(N_i, N_j, max_tau)\n",
    "                #Now we store the results\n",
    "                max_corr = np.max(cross_corrs)\n",
    "                if max_corr >= threshold:\n",
    "                    adjacency_matrix[i,j] = max_corr\n",
    "\n",
    "\n",
    "adj_data = pd.DataFrame(adjacency_matrix, index=subset_columns, columns=subset_columns)\n",
    "print(adj_data)\n",
    "\n",
    "#Okkei now we try another approach, batch processing, we divide the computation in different parts, and then merge the results.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
