{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25981d-a03b-4590-a140-5d29f13e525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import correlate\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import lil_matrix\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "from datetime import datetime, timedelta\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "# Load the temporal series data\n",
    "data_with_date = pd.read_csv('temporal_series_8.csv')\n",
    "data = data_with_date.drop(columns=['date'])\n",
    "\n",
    "#Inizialize parameters\n",
    "max_tau = 15 \n",
    "threshold = 0.05\n",
    "\n",
    "#Function to compute maximum of time correlation function between two temporal series\n",
    "def time_delayed_cross_correlation(df, col1, col2, max_tau, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Optimized custom time-delayed cross-correlation function for two time series.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): Dataframe containing the time series data.\n",
    "    col1 (str): Name of the first time series column.\n",
    "    col2 (str): Name of the second time series column.\n",
    "    max_tau (int): Maximum time delay (positive or negative).\n",
    "    threshold (float): Threshold for maximum correlation.\n",
    "\n",
    "    Returns:\n",
    "    float: Maximum cross-correlation above the threshold, or 0 if none.\n",
    "    \"\"\"\n",
    "    # Extract the series and compute means and std deviations\n",
    "    series_i = df[col1].values\n",
    "    series_j = df[col2].values\n",
    "    mean_i, std_i = series_i.mean(), series_i.std()\n",
    "    mean_j, std_j = series_j.mean(), series_j.std()\n",
    "    \n",
    "    # Check if standard deviations are zero to avoid division by zero\n",
    "    if std_i == 0 or std_j == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Initialize array to store cross-correlations for each lag\n",
    "    cross_corrs = np.zeros(2 * max_tau + 1)\n",
    "\n",
    "    # Compute cross-correlation for each lag\n",
    "    for tau in range(-max_tau, max_tau + 1):\n",
    "        if tau < 0:\n",
    "            # Positive lag: shift series_j forward by -tau (series_i aligns with delayed series_j)\n",
    "            numerator = np.sum((series_i[-tau:] - mean_i) * (series_j[:len(series_j) + tau] - mean_j))\n",
    "            denominator = (std_i * std_j * (len(series_i) + tau))\n",
    "        else:\n",
    "            # Negative or zero lag: shift series_i forward by tau (series_j aligns with delayed series_i)\n",
    "            numerator = np.sum((series_i[:len(series_i) - tau] - mean_i) * (series_j[tau:] - mean_j))\n",
    "            denominator = (std_i * std_j * (len(series_i) - tau))\n",
    "\n",
    "        # Calculate cross-correlation, check for zero denominator\n",
    "        cross_corrs[tau + max_tau] = numerator / denominator if denominator != 0 else 0\n",
    "\n",
    "    # Find the maximum correlation and compare with threshold\n",
    "    max_corr = np.max(cross_corrs)\n",
    "    max_index = np.argmax(cross_corrs)\n",
    "    best_tau = max_index - max_tau  # Convert array index back to tau value\n",
    "\n",
    "    # Apply threshold check and adjust max_corr based on tau direction\n",
    "    if max_corr >= threshold:\n",
    "        return max_corr if best_tau >= 0 else -max_corr\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "#Function to compute the whole adjacency matrix (impossible to compute)\n",
    "def ccr_matrix(df):\n",
    "    #build the adjacency matrix\n",
    "    adjacency_matrix = pd.DataFrame(np.nan, index=df.columns, columns=df.columns)\n",
    "\n",
    "    #iterate for each pair of columns\n",
    "    for col1 in df.columns:\n",
    "        for col2 in df.columns:\n",
    "            adjacency_matrix.loc[col1,col2] = time_delayed_cross_correlation(df, col1, col2, max_tau)\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "#function to compute just a submatrix of the adjacency matrix (submatricese on the diagonal)\n",
    "def compute_submatrix(df, columns, filename, max_tau):\n",
    "    submatrix = pd.DataFrame(index=columns, columns=columns)\n",
    "\n",
    "    # Loop through column pairs, skipping redundant calculations\n",
    "    for col1, col2 in product(columns, repeat=2):\n",
    "        if col1 <= col2:  # Ensures each pair is calculated only once\n",
    "            correlation = time_delayed_cross_correlation(df, col1, col2, max_tau)\n",
    "            submatrix.loc[col1, col2] = correlation\n",
    "            submatrix.loc[col2, col1] = correlation  # Fill symmetric position\n",
    "\n",
    "    submatrix.to_csv(filename)\n",
    "    print(f\"Submatrix {filename} has been saved.\")\n",
    "    return submatrix\n",
    "\n",
    "#function to computer a submatrix which is not on the diagonal\n",
    "def compute_cross_group_matrix(df, group_a, group_b, filename):\n",
    "    cross_matrix = pd.DataFrame(index=group_a, columns=group_b)\n",
    "    for col1, col2 in product(group_a, group_b):\n",
    "        cross_matrix.loc[col1, col2] = time_delayed_cross_correlation(df, col1, col2, max_tau)\n",
    "    cross_matrix.to_csv(filename)\n",
    "    print(f\"submatrix{filename} has been saved\")\n",
    "    return cross_matrix\n",
    "\n",
    "#Now to compute the submatrices we need to divide the 3104 columns into groups\n",
    "def divide_into_groups(df, group_sizes):\n",
    "    #Divides the comlumns into specified sizes\n",
    "    columns = df.columns.tolist()\n",
    "    groups = []\n",
    "    start = 0\n",
    "    for size in group_sizes:\n",
    "        groups.append(columns[start:start + size])\n",
    "        start += size\n",
    "    return groups\n",
    "\n",
    "#Change of program, now we will try to compute manually the single pieces\n",
    "group_1 = data.columns[0:1000]\n",
    "group_2 = data.columns[1000:2000]\n",
    "group_3 = data.columns[2000:3104]\n",
    "\n",
    "\n",
    "filename_sub = \"8_sub_mat_3.csv\"\n",
    "compute_submatrix(data, group_3, filename_sub, max_tau)\n",
    "\n",
    "#filename_cross = \"7_cross_matrix_2_3.csv\"\n",
    "#compute_cross_group_matrix(data, group_2, group_3, filename_cross)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
